{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-mkdocs","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"serving/00_serving_tools/","title":"MLServer vs Ray Serve","text":""},{"location":"serving/00_serving_tools/#overview-of-mlserver-and-ray-serve","title":"Overview of MLServer and Ray Serve","text":"<p>The following comparison between MLServer and Ray Serve covers different use cases  and scenarios to highlight the strengths and drawbacks of each. You can follow along  in a notebook locally, on Google Colab, or via a GitHub Codespace using the boxes  above.</p> <p>Let's get started!</p>"},{"location":"serving/00_serving_tools/#installation","title":"Installation","text":"MLServerRay Serve <pre><code>pip install mlserver mlserver-huggingface\n</code></pre> <pre><code>pip install \"ray[serve]\" transformers\n</code></pre>"},{"location":"serving/00_serving_tools/#import-packages","title":"Import Packages","text":"MLServerRay Serve <pre><code>import mlserver\n</code></pre> <pre><code>import serve\n</code></pre>"},{"location":"serving/00_serving_tools/#serving-a-model","title":"Serving a Model","text":"<p>With Ray you can create an app as a regular Python file and define a class  that will load your model and run inference with it. The class will get a <code>serve</code> decorator  to indicate ray what object in your Python file will become a service. </p> <p>```python</p>"},{"location":"serving/00_serving_tools/#file-name-serve_deploymentpy","title":"File name: serve_deployment.py","text":"<p>from starlette.requests import Request from transformers import pipeline from ray import serve import ray</p> <p>@serve.deployment(num_replicas=2, ray_actor_options={\"num_cpus\": 0.2, \"num_gpus\": 0}) class Translator:     def init(self):         # Load model         self.model = pipeline(\"translation_en_to_fr\", model=\"t5-small\")</p> <pre><code>def translate(self, text: str) -&gt; str:\n    # Run inference\n    model_output = self.model(text)\n\n    # Post-process output to return only the translation text\n    translation = model_output[0][\"translation_text\"]\n\n    return translation\n\nasync def __call__(self, http_request: Request) -&gt; str:\n    english_text: str = await http_request.json()\n    return self.translate(english_text)\n</code></pre> <p>translator_app = Translator.bind() ``</p>"}]}